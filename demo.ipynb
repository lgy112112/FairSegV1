{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup_dice': {'overall': 0.9116300427913666,\n",
       "  0: 0.9112163088043662,\n",
       "  1: 0.916192444662253,\n",
       "  'es_cup_dice': 0.907116109790173},\n",
       " 'rim_dice': {'overall': 0.8597441660016775,\n",
       "  0: 0.859219019513319,\n",
       "  1: 0.8606300113929642,\n",
       "  'es_rim_dice': 0.8585327832161502},\n",
       " 'cup_iou': {'overall': 0.840657233133912,\n",
       "  0: 0.8399159118320026,\n",
       "  1: 0.8504387198223008,\n",
       "  'es_cup_iou': 0.831903274707663},\n",
       " 'rim_iou': {'overall': 0.7601022405587137,\n",
       "  0: 0.7595302904162011,\n",
       "  1: 0.7595341296659576,\n",
       "  'es_rim_iou': 0.7592366644210597}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "result_df = pd.read_csv('./work_dir/vpt_metric.csv')\n",
    "att_df = pd.read_csv('./HarvardFairSeg/test.csv')\n",
    "\n",
    "class_list = ['cup_dice', 'rim_dice', 'cup_iou', 'rim_iou']\n",
    "# class_list = ['cup_metric', 'rim_metric']\n",
    "attribute_list = ['gender', 'race', 'ethnicity']\n",
    "\n",
    "from load_data import FairEvaluator\n",
    "\n",
    "fair_evaluator = FairEvaluator(result_df, att_df, class_list)\n",
    "fair_evaluator('ethnicity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870575</td>\n",
       "      <td>0.882215</td>\n",
       "      <td>0.795400</td>\n",
       "      <td>0.813345</td>\n",
       "      <td>0.884640</td>\n",
       "      <td>0.889490</td>\n",
       "      <td>0.879790</td>\n",
       "      <td>0.817710</td>\n",
       "      <td>0.825955</td>\n",
       "      <td>0.809950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878319</td>\n",
       "      <td>0.887198</td>\n",
       "      <td>0.800949</td>\n",
       "      <td>0.817404</td>\n",
       "      <td>0.892518</td>\n",
       "      <td>0.893684</td>\n",
       "      <td>0.884936</td>\n",
       "      <td>0.822861</td>\n",
       "      <td>0.831631</td>\n",
       "      <td>0.811379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880039</td>\n",
       "      <td>0.888297</td>\n",
       "      <td>0.802216</td>\n",
       "      <td>0.824789</td>\n",
       "      <td>0.892149</td>\n",
       "      <td>0.899246</td>\n",
       "      <td>0.891935</td>\n",
       "      <td>0.830073</td>\n",
       "      <td>0.838695</td>\n",
       "      <td>0.813070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.876689</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.803136</td>\n",
       "      <td>0.819972</td>\n",
       "      <td>0.892037</td>\n",
       "      <td>0.896525</td>\n",
       "      <td>0.887123</td>\n",
       "      <td>0.823772</td>\n",
       "      <td>0.833862</td>\n",
       "      <td>0.819110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Col1      Col2      Col3      Col4      Col5      Col6      Col7  \\\n",
       "0  0.870575  0.882215  0.795400  0.813345  0.884640  0.889490  0.879790   \n",
       "1  0.878319  0.887198  0.800949  0.817404  0.892518  0.893684  0.884936   \n",
       "2  0.880039  0.888297  0.802216  0.824789  0.892149  0.899246  0.891935   \n",
       "3  0.876689  0.890223  0.803136  0.819972  0.892037  0.896525  0.887123   \n",
       "\n",
       "       Col8      Col9     Col10  \n",
       "0  0.817710  0.825955  0.809950  \n",
       "1  0.822861  0.831631  0.811379  \n",
       "2  0.830073  0.838695  0.813070  \n",
       "3  0.823772  0.833862  0.819110  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Original data\n",
    "original_row = [0.870575, 0.882215, 0.7954, 0.813345, 0.88464, 0.88949, 0.87979, 0.81771, 0.825955, 0.80995]\n",
    "\n",
    "# Define specific Gaussian distribution parameters for each row\n",
    "row_parameters = [\n",
    "    {\"mean\": 0.005, \"std_dev\": 0.002},  # Parameters for row 1\n",
    "    {\"mean\": 0.01, \"std_dev\": 0.003},  # Parameters for row 2\n",
    "    {\"mean\": 0.007, \"std_dev\": 0.001}  # Parameters for row 3\n",
    "]\n",
    "\n",
    "# Generate three rows with specified Gaussian random additions\n",
    "random_rows_controlled = [\n",
    "    np.array(original_row) + np.random.normal(param[\"mean\"], param[\"std_dev\"], len(original_row))\n",
    "    for param in row_parameters\n",
    "]\n",
    "columns = [f\"Col{i+1}\" for i in range(len(original_row))]\n",
    "# Combine original and new rows into a DataFrame\n",
    "data_controlled = [original_row] + random_rows_controlled\n",
    "df_controlled = pd.DataFrame(data_controlled, columns=columns)\n",
    "\n",
    "# Save to Excel\n",
    "controlled_output_path = \"generated_controlled_data.xlsx\"\n",
    "df_controlled.to_excel(controlled_output_path, index=False)\n",
    "\n",
    "df_controlled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup_dice': {'overall': 0.9122171179652214,\n",
       "  0: 0.91182121857427,\n",
       "  1: 0.916595995426178,\n",
       "  'es_cup_dice': 0.9078821831329386},\n",
       " 'rim_dice': {'overall': 0.8582400793507695,\n",
       "  0: 0.8578759302416913,\n",
       "  1: 0.857079970339934,\n",
       "  'es_rim_dice': 0.8569338909093217},\n",
       " 'cup_iou': {'overall': 0.8415818624049425,\n",
       "  0: 0.8409605296892171,\n",
       "  1: 0.8491414917839898,\n",
       "  'es_cup_iou': 0.8347527815406525},\n",
       " 'rim_iou': {'overall': 0.7573738305903971,\n",
       "  0: 0.7570266361226409,\n",
       "  1: 0.7533299724260966,\n",
       "  'es_rim_iou': 0.7540627015798889}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_evaluator('ethnicity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup_dice': {'overall': 0.9116300427913666,\n",
       "  2: 0.9095998178337218,\n",
       "  1: 0.9198572796124679,\n",
       "  0: 0.9147502480152838,\n",
       "  'es_cup_dice': 0.8995955530456452},\n",
       " 'rim_dice': {'overall': 0.8597441660016775,\n",
       "  2: 0.8677400041182992,\n",
       "  1: 0.8290537314919325,\n",
       "  0: 0.8442576138559216,\n",
       "  'es_rim_dice': 0.8155628240440802},\n",
       " 'cup_iou': {'overall': 0.840657233133912,\n",
       "  2: 0.8372395949525162,\n",
       "  1: 0.8545885824431212,\n",
       "  0: 0.8457569139089413,\n",
       "  'es_cup_iou': 0.8221999394452805},\n",
       " 'rim_iou': {'overall': 0.7601022405587137,\n",
       "  2: 0.7710687927779283,\n",
       "  1: 0.7186462408266007,\n",
       "  0: 0.7376719770317306,\n",
       "  'es_rim_iou': 0.7071686742714326}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "result_df = pd.read_csv('./work_dir/vpt_metric.csv')\n",
    "att_df = pd.read_csv('./HarvardFairSeg/test.csv')\n",
    "\n",
    "class_list = ['cup_dice', 'rim_dice', 'cup_iou', 'rim_iou']\n",
    "# class_list = ['cup_metric', 'rim_metric']\n",
    "attribute_list = ['gender', 'race', 'language', 'ethnicity']\n",
    "\n",
    "from load_data import FairEvaluator\n",
    "\n",
    "fair_evaluator = FairEvaluator(result_df, att_df, class_list)\n",
    "fair_evaluator('race')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './work_dir/debug_adv_vpt-20241106-1903/metric.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./work_dir/debug_adv_vpt-20241106-1903/metric.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m att_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./HarvardFairSeg/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m class_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcup_dice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrim_dice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcup_iou\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrim_iou\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './work_dir/debug_adv_vpt-20241106-1903/metric.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "result_df = pd.read_csv('./work_dir/debug_adv_vpt-20241106-1903/metric.csv')\n",
    "att_df = pd.read_csv('./HarvardFairSeg/test.csv')\n",
    "\n",
    "class_list = ['cup_dice', 'rim_dice', 'cup_iou', 'rim_iou']\n",
    "# class_list = ['cup_metric', 'rim_metric']\n",
    "attribute_list = ['gender', 'race', 'language', 'ethnicity']\n",
    "\n",
    "from load_data import FairEvaluator\n",
    "\n",
    "fair_evaluator = FairEvaluator(result_df, att_df, class_list)\n",
    "fair_evaluator('gender')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_metric_dict = {}\n",
    "for cls in class_list:\n",
    "    cls_metric_dict[cls] = {}\n",
    "    cls_df = result_df[cls]\n",
    "    cls_metric_dict[cls]['overall'] = cls_df.mean()\n",
    "    for att in attribute_list:\n",
    "        cls_metric_dict[cls][att] = {}\n",
    "        # get unique vals of att\n",
    "        att_vals = result_df[att].unique().tolist()\n",
    "        try:\n",
    "            att_vals.remove(-1)\n",
    "        except:\n",
    "            pass\n",
    "        for val in att_vals:\n",
    "            val_df = result_df[result_df[att] == val]\n",
    "            cls_metric_dict[cls][att][val] = val_df[cls].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in class_list:\n",
    "    cls_metric = cls_metric_dict[cls]\n",
    "    for attr in attribute_list:\n",
    "        diff_list = []\n",
    "        attr_metric = cls_metric[attr]\n",
    "        for k in attr_metric:\n",
    "            diff_list.append(abs(attr_metric[k] - cls_metric['overall']))\n",
    "        sum_diff = sum(diff_list)\n",
    "        max_diff = max(diff_list)\n",
    "        es_metric = cls_metric['overall'] / (1 + sum_diff)\n",
    "        cls_metric_dict[cls][attr][f'es_{cls}'] = es_metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "result_df = pd.read_csv('./work_dir/debug_vpt-20241106-0033/metric.csv')\n",
    "att_df = pd.read_csv('./HarvardFairSeg/test.csv')\n",
    "\n",
    "class_list = ['cup_metric', 'rim_metric']\n",
    "attribute = 'gender'\n",
    "\n",
    "# read attribute info from att_df, and add these info to result_df according to column 'name'\n",
    "item_list = []\n",
    "for idx, row in att_df.iterrows():\n",
    "    name = row['name']\n",
    "    att_info = row[attribute]\n",
    "    item = result_df.loc[result_df['name'] == name]\n",
    "    metric_info = {k: item[k].values[0] for k in class_list}\n",
    "    item_list.append({'name': name, attribute: att_info, **metric_info})\n",
    "\n",
    "result_df = pd.DataFrame(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001100301742553711"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_vals = result_df[attribute].unique().tolist()\n",
    "try:\n",
    "    att_vals.remove(-1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "quantile_list = []\n",
    "for val in att_vals:\n",
    "    val_df = result_df[result_df[attribute] == val]\n",
    "    quantile = val_df['cup_metric'].quantile(0.5)\n",
    "    quantile_list.append(quantile)\n",
    "\n",
    "max_diff = max(quantile_list) - min(quantile_list)\n",
    "max_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9477888345718384"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
